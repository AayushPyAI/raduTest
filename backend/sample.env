# =============================================================================
# Patent Search Backend - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your actual values
# DO NOT commit .env files with real secrets to version control

# -----------------------------------------------------------------------------
# Server Configuration
# -----------------------------------------------------------------------------
NODE_ENV=development
PORT=8000
CORS_ORIGINS=http://localhost:3005,http://localhost:3001,http://localhost:3002

# -----------------------------------------------------------------------------
# Google Cloud Configuration
# -----------------------------------------------------------------------------
# Your Google Cloud project ID for billing BigQuery queries
GOOGLE_CLOUD_PROJECT_ID=your-gcp-project-id

# Path to your Google Cloud service account key file (optional - can use ADC)
GOOGLE_CLOUD_KEY_FILE=./service-account-key.json

# -----------------------------------------------------------------------------
# BigQuery Configuration
# -----------------------------------------------------------------------------
# Google Patents public dataset (don't change this)
BIGQUERY_DATASET=patents-public-data.patents

# BigQuery location/region
BIGQUERY_LOCATION=US

# Maximum results per BigQuery query
BIGQUERY_MAX_RESULTS=1000

# -----------------------------------------------------------------------------
# Pinecone Vector Database Configuration
# -----------------------------------------------------------------------------
# Get from: https://app.pinecone.io/
PINECONE_API_KEY=your-pinecone-api-key

# Pinecone environment/region
PINECONE_ENVIRONMENT=us-east-1

# Your Pinecone index name
PINECONE_INDEX_NAME=your-index-name

# Pinecone index host URL (optional - auto-detected)
PINECONE_HOST=https://your-index-host.pinecone.io

# Vector similarity metric (dotproduct for sparse vectors)
PINECONE_METRIC=dotproduct

# Embedding model for Pinecone Inference API
PINECONE_MODEL=pinecone-sparse-english-v0

# Vector type (sparse or dense)
PINECONE_TYPE=sparse

# Cloud provider
PINECONE_CLOUD=aws

# Cloud region
PINECONE_REGION=us-east-1

# -----------------------------------------------------------------------------
# OpenAI Configuration (Optional - used for some features)
# -----------------------------------------------------------------------------
# Get from: https://platform.openai.com/account/api-keys
OPENAI_API_KEY=your-openai-api-key

# GPT model for text analysis
OPENAI_MODEL=gpt-4o

# Embedding model (if using OpenAI instead of Pinecone)
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Maximum tokens for OpenAI requests
OPENAI_MAX_TOKENS=4000

# -----------------------------------------------------------------------------
# Firebase Authentication Configuration
# -----------------------------------------------------------------------------
# Get from: Firebase Console > Project Settings > General
FIREBASE_PROJECT_ID=your-firebase-project-id

# Service account credentials (optional - for admin operations)
FIREBASE_CLIENT_EMAIL=your-service-account@your-project.iam.gserviceaccount.com
FIREBASE_PRIVATE_KEY="-----BEGIN PRIVATE KEY-----\nyour-private-key\n-----END PRIVATE KEY-----\n"

# Firebase database URL (optional)
FIREBASE_DATABASE_URL=https://your-project.firebaseio.com

# -----------------------------------------------------------------------------
# Logging Configuration
# -----------------------------------------------------------------------------
# Log level: error, warn, info, debug
LOG_LEVEL=info

# Log format: combined, common, dev, short, tiny
LOG_FORMAT=combined

# -----------------------------------------------------------------------------
# Cache Configuration
# -----------------------------------------------------------------------------
# Cache TTL in seconds (1 hour = 3600)
CACHE_TTL=3600

# Maximum cache size (number of items)
CACHE_MAX_SIZE=1000 